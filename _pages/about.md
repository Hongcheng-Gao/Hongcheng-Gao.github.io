---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<!-- {% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %} -->

<span class='anchor' id='about-me'></span>

<p>Hongcheng Gao(È´òÈ∏øÊàê) is an incoming PhD student at <a href="https://collegeai.tsinghua.edu.cn/"> College of AI</a> at <a href="https://www.tsinghua.edu.cn/">Tsinghua University</a>. He may receive his M.S. degree in July 2026. He received his Bachelor's degree of Computer Science and Technology at <a href="https://cqu.edu.cn/">Chongqing University</a> in June 2023. </p>

His research interests include **large reasoning models**, **AI agents** and **unified models**, spanning both textual and multimodal domains (especially *spatial* tasks).

*His team is looking for collaborators and interns. Please feel free to reach out.*


# üî• News
- *2026.1*: One papers accepted to ICLR'26.
- *2025.11*: One papers accepted to AAAI'26.
- *2025.09*: Two papers accepted to Neurips'25 with one **Oral**.
- *2025.06*: One paper accepted to ICCV 2025.
- *2025.06*: Invited to serve as **Senior PC Member** for CIKM'25. 

- *2025.01*: Two papers accepted to ICLR 2025 with one **Oral**.
- *2024.10*: Selected as NeurIPS 2024 **Top Reviewer**. 
- *2024.09*: Three papers accepted to NeurIPS 2024 with **two Spotlights**.
- *2024.09*: Two papers accepted to EMNLP 2024.
- *2024.05*: One paper accepted to ACL 2024.
- *2024.04*: One paper accepted to NAACL 2024.
- *2024.01*: üéâ One paper accepted to ICLR 2024.
- *2023.09*: üéâ One paper accepted to NeurIPS 2023 (D&B Track).
- *2023.05*: üéâ One paper accepted to ACL 2023!
- *2022.10*: üéâ Two papers accepted by EMNLP 2022!
- *2022.08*: üéâ One paper accepted by NAACL 2022!
<!-- - *2022.06*: &nbsp;üéâüéâ Our textual backdoor learning toolkit *OpenBackdoor* has been released. Please check out [here](https://github.com/thunlp/OpenBackdoor)! -->





# üìù Preprints 
\* indicates equal contribution.

- **GuardReasoner: Towards Reasoning-based LLM Safeguards** [\[Paper\]](https://arxiv.org/abs/2501.18492)<br>
Yue Liu, **Hongcheng Gao**, Shengfang Zhai, Jun Xia, Tianyi Wu, Zhiwei Xue, Yulin Chen, Kenji Kawaguchi, Jiaheng Zhang, Bryan Hooi

- **StruEdit: Structured Outputs Enable the Fast and Accurate Knowledge Editing for Large Language Models** [\[Paper\]](https://arxiv.org/abs/2409.10132)<br>
Baolong Bi, Shenghua Liu, Yiwei Wang, Lingrui Mei, **Hongcheng Gao**, Junfeng Fang, Xueqi Cheng

- **Evaluating the Robustness of Text-to-image Diffusion Models against Real-world Attacks** [\[Paper\]](https://arxiv.org/abs/2306.13103)<br> 
**Hongcheng Gao**, Hao Zhang, Yinpeng Dong, Zhijie Deng. <br>

- **Kimi k1. 5: Scaling Reinforcement Learning with LLMs** [\[Paper\]](https://arxiv.org/abs/2501.12599)<br>
**Kimi Team**

- **Kimi-vl Technical Report** [\[Paper\]](https://arxiv.org/abs/2504.07491)<br>
**Kimi Team**

- **Kimi k2: Open Agentic Intelligence** [\[Paper\]](https://arxiv.org/abs/2507.20534)<br>
**Kimi Team**

- **Kimi k2.5: Visual Agentic intelligence** [\[Paper\]](https://github.com/MoonshotAI/Kimi-K2.5/blob/master/tech_report.pdf)<br>
**Kimi Team**
  
<!-- *Under Review by **NeurIPS 2023*** -->

<!-- *Under Review by **NeurIPS 2023*** -->

<!-- *Under Review by **NeurIPS 2023*** -->

<!-- - **DEPP: A Novel Crystal Descriptor and Application in Ionic Batteries Voltage Prediction** <br>
Dongchen Jin\*, **Hongcheng Gao\***, Haoran Luo\*, Linlin He, Chao Yang, Yujie Zheng. <br>
*Under Review by **npj Computational Materials** (Sister journal of **<font color="dd0000">Nature</font>**)* -->


# üìù Publications 
\* indicates equal contribution.

<!-- <table><tr><td>
    <img src="../images/calibration.png" style="border:1.2px solid #464646;padding:5px;border-radius:10px;box-shadow:1.2px 1.2px #bbbbbb" alt="" width="450px" />&nbsp;</td>
    <td align="left">
    <p>
      <b>A Close Look into the Calibration of Pre-trained Language Models</b>. <a href="https://arxiv.org/abs/2211.00151">[Paper]</a><br>
      Yangyi Chen*, <b>Lifan Yuan*</b>, Ganqu Cui, Zhiyuan Liu, Heng Ji. <br>
      <em><b>What</b></em>: An emperical study on the calibration of PLMs and existing calibration methods. <br>
      <em><b>Results</b></em>: Language models do not learn to be calibrated in training, and existing methods fail to tackle the miscalibration problems.<br>
      <em><b>Insights</b></em>: Learnable calibration methods, which directly collect data to train PLMs on the calibration task, demonstrate a great potential in improving PLMs' calibration.<br>
    </p>
</td></tr></table> -->

**2025**

- **How Far Are LLMs from Professional Poker Players? Revisiting Game-Theoretic Reasoning with Agentic Tool Use** [\[Paper\]](https://openreview.net/forum?id=vV54ShHvGi)<br>
Minhua Lin, Enyan Dai, Hui Liu, Xianfeng Tang, Yuliang Yan, Zhenwei Dai, Jingying Zeng, Zhiwei Zhang, Fali Wang, **Hongcheng Gao**, Chen Luo, Xiang Zhang, Qi He, Suhang Wang. <br>
***ICLR 2026***

- **Representation Entanglement for Generation: Training Diffusion Transformers Is Much Easier Than You Think** [\[Paper\]](https://arxiv.org/abs/2507.01467)<br>
Ge Wu, Shen Zhang, Ruijing Shi, Shanghua Gao, Zhenyuan Chen, Lei Wang, Zhaowei Chen, **Hongcheng Gao**, Yao Tang, Jian Yang, Ming-Ming Cheng, Xiang Li. <br>
***NeurIPS 2025***

- **Guardreasoner-vl: Safeguarding vlms via reinforced reasoning** [\[Paper\]](https://arxiv.org/abs/2505.11049)<br>
Yue Liu, Shengfang Zhai, Mingzhe Du, Yulin Chen, Tri Cao, **Hongcheng Gao**, Cheng Wang, Xinfeng Li, Kun Wang, Junfeng Fang, Jiaheng Zhang, Bryan Hooi<br>
***NeurIPS 2025***

- **Meta-Unlearning on Diffusion Models: Preventing Relearning Unlearned Concepts** [\[Paper\]](https://arxiv.org/abs/2410.12777)<br>
**Hongcheng Gao\***, Tianyu Pang\*, Chao Du, Taihang Hu, Zhijie Deng, Min Lin. <br>
***ICCV 2025***
  
- **Spider 2.0: Evaluating language models on real-world enterprise text-to-sql workflows** [\[Paper\]](https://arxiv.org/abs/2411.07763)<br>
Fangyu Lei\*, Jixuan Chen\*, Yuxiao Ye, Ruisheng Cao, Dongchan Shin, Hongjin Su, Zhaoqing Suo, **Hongcheng Gao**, Wenjing Hu, Pengcheng Yin, Victor Zhong, Caiming Xiong, Ruoxi Sun, Qian Liu, Sida Wang, Tao Yu. <br>
***ICLR 2025***

- **Is factuality decoding a free lunch for llms? evaluation on knowledge editing benchmark** [\[Paper\]](https://arxiv.org/abs/2404.00216)<br>
Baolong Bi, Shenghua Liu, Yiwei Wang, Lingrui Mei, Junfeng Fang, **Hongcheng Gao**, Shiyu Ni, Xueqi Cheng. <br>
***ICLR 2025***



**2024**
- **Spider2-V: How Far Are Multimodal Agents From Automating Data Science and Engineering Workflows?** [\[Paper\]](https://arxiv.org/abs/2406.13233)<br>
Ruisheng Cao, Fangyu Lei, Haoyuan Wu, Jixuan Chen, Yeqiao Fu, **Hongcheng Gao** et al. <br>
***NeurIPS 2024(SpotlightÔºâ***

- **Leveraging Catastrophic Forgetting to Develop Safe Diffusion Models against Malicious Finetuning**[\[Paper\]](https://proceedings.neurips.cc/paper_files/paper/2024/hash/d0949cbcec31c09431610553a284f94a-Abstract-Conference.html)<br>
Jiadong Pan\*, **Hongcheng Gao\***, Zongyu Wu, Tanghang Hu, Li Su, Qingming Huang, Liang Li. <br>
***NeurIPS 2024(SpotlightÔºâ***

- **Token Merging for Training-Free Semantic Binding in Text-to-Image Synthesis**[\[Paper\]](https://arxiv.org/abs/2411.07132)<br>
Taihang Hu, Linxuan Li, Joost van de Weijer, **Hongcheng Gao**, Fahad Shahbaz Khan, Jian Yang, Ming-Ming Cheng, Kai Wang, Yaxing Wang. <br>
***NeurIPS 2024***

- **AdaMoE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models** [\[Paper\]](https://arxiv.org/abs/2406.13233)<br>
Zihao Zeng\*, Yibo Miao\*, **Hongcheng Gao**, Hao Zhang, Zhijie Deng. <br>
*Findings of **EMNLP 2024***.<br>

- **Adaptive Token Biaser: Knowledge Editing via Biasing Key Entities** [\[Paper\]](https://arxiv.org/abs/2406.12468)<br> 
Baolong Bi, Shenghua Liu, Yiwei Wang, Lingrui Mei, **Hongcheng Gao**, Yilong Xu, Xueqi Cheng. <br>
*Findings of **EMNLP 2024***.<br>

- **Efficient Detection of LLM-generated Texts with a Bayesian Surrogate Model** [\[Paper\]](https://arxiv.org/abs/2305.16617)<br>
Zhijie Deng\*, **Hongcheng Gao\***, Yibo Miao, Hao Zhang. <br>
*Findings of **ACL 2024***.<br>

- **Universal Prompt Optimizer for Safe Text-to-Image Generation** [\[Paper\]](https://arxiv.org/abs/2402.10882)<br> 
Zongyu Wu\*, **Hongcheng Gao\***, Yueze Wang, Xiang Zhang, Suhang Wang. <br>
***NAACL 2024***

- **Generative Pretraining in Multimodality** [\[Paper\]](https://arxiv.org/abs/2307.05222)<br> 
Quan Sun\*, Qiying Yu\*, Yufeng Cui\*, Fan Zhang\*, Xiaosong Zhang\*, Yueze Wang, **Hongcheng Gao**, Jingjing Liu, Tiejun Huang, Xinlong Wang<br>
***ICLR 2024***

**2023**

- **Revisiting Out-of-distribution Robustness in NLP: Benchmark, Analysis, and LLMs Evaluations** [\[Paper\]](http://arxiv.org/abs/2306.04618)<br>
Lifan Yuan, Yangyi Chen, Ganqu Cui, **Hongcheng Gao**, Fangyuan Zou, Xingyi Cheng, Heng Ji, Zhiyuan Liu, Maosong Sun. <br>
***NeurIPS 2023 (D&B Track)***

- **From Adversarial Arms Race to Model-centric Evaluation: Motivating a Unified Automatic Robustness Evaluation Framework** [\[Paper\]](https://arxiv.org/abs/2305.18503)<br>
Yangyi Chen\*, **Hongcheng Gao\***, Ganqu Cui\*, Lifan Yuan, Dehan Kong, Hanlu Wu, Ning Shi, Bo Yuan, Longtao Huang, Hui Xue, Zhiyuan Liu, Maosong Sun, Heng Ji. <br>
*Findings of **ACL 2023***.<br>

**2022**

- **Why Should Adversarial Perturbations be Imperceptible? Rethink the Research Paradigm in Adversarial NLP** [\[Paper\]](https://arxiv.org/abs/2210.10683)<br>
Yangyi Chen\*, **Hongcheng Gao\***, Ganqu Cui, Fanchao Qi, Longtao Huang, Zhiyuan Liu, Maosong Sun. <br>
***EMNLP 2022***.<br>

- **Textual Backdoor Attacks Can Be More Harmful via Two Simple Tricks** [\[Paper\]](https://arxiv.org/abs/2110.08247)<br>
Yangyi Chen\*, Fanchao Qi\*, **Hongcheng Gao**, Zhiyuan Liu, Maosong Sun. <br>
***EMNLP 2022***.<br>


- **Exploring the Universal Vulnerability of Prompt-based Learning Paradigm** [\[Paper\]](https://aclanthology.org/2022.findings-naacl.137)<br>
Lei Xu, Yangyi Chen, Ganqu Cui, **Hongcheng Gao**, Zhiyuan Liu.<br>
*Findings of **NAACL 2022***.<br>


# üíª Projects

- [RobTest](https://github.com/thunlp/RobTest): an open-source toolkit for textual model robustness evaluation .<br>
- [Spider2-V](https://github.com/xlang-ai/Spider2-V): Spider2-V is a multimodal agent benchmark spanning across the entire data science and engineering workflow 
- [OpenAttack](https://github.com/thunlp/OpenAttack): an open-source Python-based textual adversarial attack toolkit.<br>
- [Emu](https://github.com/baaivision/Emu): an open multimodal generalist for both image-to-text and text-to-image tasks. <br>

# üìÑ Academic Services
- Area Chiar/Senior PC Member:
  - 2025: NeurIPS, CIKM

- Reviewer/PC Member:
  - 2025: ICML, AISTATS, ICCV, ACL, ARR, ECAI<br>
  - 2024: NeurIPS(**Top Reviewer**), ICLR, CVPR, ACL, EMNLP, NAACL, ARR, Machine Learning, AISTATS.

<!-- # üìÑ Academic Services
- Journey Reviews:
<a href="https://www.springer.com/journal/10994">Machine Learning</a>,  -->

<!-- **Conference Reviews**

2023: ACL, ARR.

2022: NeurIPS, EMNLP, ARR. --> 


<!-- # üéñ Honors and Awards
- Outstanding Graduate, HUST, 2023
- Optics Valley Morning Star Scholarship, China Optics Valley, 2022
- Scholarship for Scientific and Technological Innovation, HUST, 2022
- National Scholarship, China, 2020
- Outstanding Undergraduate, HUST, 2020
- Merit Student, HUST, 2020
- First Prize in Provinces, Chinese Chemistry Olympiad, 2018 -->

# üìñ Experiences

- *2018.09 - 2023.06*, Undergraduate Student at Chongqing University.
- *2021.06 - 2023.06*, Intern at THUNLP, Tsinghua University. Mentor: <a href="http://nlp.csai.tsinghua.edu.cn/~lzy/">Prof. Zhiyuan Liu</a>

<!-- # üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# üíª Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China. -->
