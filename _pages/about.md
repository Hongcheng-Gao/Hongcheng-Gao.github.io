---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<!-- {% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %} -->

<span class='anchor' id='about-me'></span>

<p>Hongcheng Gao(È´òÈ∏øÊàê) is a fourth-year undergraduate student in Computer Science at <a href="https://cqu.edu.cn/">Chongqing University</a>. 
In his undergraduate years, He was a research intern at <a href="http://nlp.csai.tsinghua.edu.cn">THUNLP</a>,  advised by <a href="http://nlp.csai.tsinghua.edu.cn/~lzy/">Prof. Zhiyuan Liu</a>.  He also worked with <a href="https://thudzj.github.io">Prof. Zhijie Deng</a>(<a href="https://www.sjtu.edu.cn">SJTU</a>) and <a href="https://people.eecs.berkeley.edu/~hao/">Prof.Hao Zhang</a>(<a href="https://www.berkeley.edu">UC Berkeley</a>).
<br>
His research interests lie in <strong>trustworthy NLP, large language modeling and multi-modal learning</strong>.
<br></p>


# üî• News
- *2023.05*: üéâOne paper is accepted to ACL 2023!
- *2022.10*: üéâTwo papers are accepted by EMNLP2022!
- *2022.08*: üéâOne paper is accepted by NAACL2022!
<!-- - *2022.06*: &nbsp;üéâüéâ Our textual backdoor learning toolkit *OpenBackdoor* has been released. Please check out [here](https://github.com/thunlp/OpenBackdoor)! -->





# üìù Preprints 
\* indicates equal contribution.

- **Revisiting Out-of-distribution Robustness in NLP: Benchmark, Analysis, and LLMs Evaluations** [\[Paper\]](http://arxiv.org/abs/2306.04618)<br>
Lifan Yuan, Yangyi Chen, Ganqu Cui, *<u>Hongcheng Gao</u>*, Fangyuan Zou, Xingyi Cheng, Heng Ji, Zhiyuan Liu, Maosong Sun

- **Efficient Detection of LLM-generated Texts with a Bayesian Surrogate Model** [\[Paper\]](https://arxiv.org/abs/2305.16617)<br>
Zhijie Deng\*, *<u>Hongcheng Gao*</u>*, Yibo Miao, Hao Zhang


# üìù Publications 
\* indicates equal contribution.

<!-- <table><tr><td>
    <img src="../images/calibration.png" style="border:1.2px solid #464646;padding:5px;border-radius:10px;box-shadow:1.2px 1.2px #bbbbbb" alt="" width="450px" />&nbsp;</td>
    <td align="left">
    <p>
      <b>A Close Look into the Calibration of Pre-trained Language Models</b>. <a href="https://arxiv.org/abs/2211.00151">[Paper]</a><br>
      Yangyi Chen*, <b>Lifan Yuan*</b>, Ganqu Cui, Zhiyuan Liu, Heng Ji. <br>
      <em><b>What</b></em>: An emperical study on the calibration of PLMs and existing calibration methods. <br>
      <em><b>Results</b></em>: Language models do not learn to be calibrated in training, and existing methods fail to tackle the miscalibration problems.<br>
      <em><b>Insights</b></em>: Learnable calibration methods, which directly collect data to train PLMs on the calibration task, demonstrate a great potential in improving PLMs' calibration.<br>
    </p>
</td></tr></table> -->

**2023**

- **From Adversarial Arms Race to Model-centric Evaluation: Motivating a Unified Automatic Robustness Evaluation Framework** [\[Paper\]](https://arxiv.org/abs/2305.18503)<br>
Yangyi Chen\*, *<u>Hongcheng Gao*</u>*, Ganqu Cui\*, Lifan Yuan, Dehan Kong, Hanlu Wu, Ning Shi, Bo Yuan, Longtao Huang, Hui Xue, Zhiyuan Liu, Maosong Sun, Heng Ji. <br>
*Findings of ACL 2023*.<br>

**2022**

- **Why Should Adversarial Perturbations be Imperceptible? Rethink the Research Paradigm in Adversarial NLP** [\[Paper\]](https://arxiv.org/abs/2208.11464)<br>
Yangyi Chen\*, *<u>Hongcheng Gao*</u>*, Ganqu Cui, Fanchao Qi, Longtao Huang, Zhiyuan Liu, Maosong Sun. <br>
*EMNLP2022*.<br>

- **Textual Backdoor Attacks Can Be More Harmful via Two Simple Tricks** [\[Paper\]](https://arxiv.org/abs/2206.08514)<br>
Yangyi Chen\*, Fanchao Qi\*, *<u>Hongcheng Gao</u>*, Zhiyuan Liu, Maosong Sun. <br>
*EMNLP2022*.<br>


- **Exploring the Universal Vulnerability of Prompt-based Learning Paradigm** [\[Paper\]](https://ieeexplore.ieee.org/abstract/document/9732198/)<br>
Lei Xu, Yangyi Chen, Ganqu Cui, *<u>Hongcheng Gao</u>*, Zhiyuan Liu.<br>
*Findings of NAACL2022*.<br>


# üíª Projects

- [RobTest](https://github.com/thunlp/RobTest): an open-source toolkit for textual model robustness evaluation .<br>
- [OpenAttack](https://github.com/thunlp/OpenAttack): an open-source Python-based textual adversarial attack toolkit.<br>

<!-- # üìÑ Academic Services

**Conference Reviews**

2023: ACL, ARR.

2022: NeurIPS, EMNLP, ARR. -->


<!-- # üéñ Honors and Awards
- Outstanding Graduate, HUST, 2023
- Optics Valley Morning Star Scholarship, China Optics Valley, 2022
- Scholarship for Scientific and Technological Innovation, HUST, 2022
- National Scholarship, China, 2020
- Outstanding Undergraduate, HUST, 2020
- Merit Student, HUST, 2020
- First Prize in Provinces, Chinese Chemistry Olympiad, 2018 -->

# üìñ Experiments

- *2018.09 - 2023.06 (Expected)*, Undergraduate Student at Chongqing University.
- *2021.06 - today*, Intern at THUNLP, Tsinghua University. Mentor: <a href="http://nlp.csai.tsinghua.edu.cn/~lzy/">Prof. Zhiyuan Liu</a>

<!-- # üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# üíª Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China. -->