---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<!-- {% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %} -->

<span class='anchor' id='about-me'></span>

<p>Hongcheng Gao(È´òÈ∏øÊàê) is a first-year Master student at <a href="https://www.ucas.ac.cn//">UCAS</a> and <a href="https://vipl.ict.ac.cn/">VIPL</a>(<a href="http://www.ict.ac.cn/">ICT</a>). He received Bachelor's degree of Computer Science and Techology at <a href="https://cqu.edu.cn/">Chongqing University</a> in 2023. 

In his undergraduate years, He was a research intern at <a href="http://nlp.csai.tsinghua.edu.cn">THUNLP</a>,  advised by <a href="http://nlp.csai.tsinghua.edu.cn/~lzy/">Prof. Zhiyuan Liu</a>.  He also worked with <a href="https://thudzj.github.io">Prof.Zhijie Deng</a>(<a href="https://www.sjtu.edu.cn">SJTU</a>), <a href="https://ml.cs.tsinghua.edu.cn/~yinpeng/">Post-doc Yinpeng Dong</a>(<a href="https://www.tsinghua.edu.cn/en/">THU</a>) and <a href="https://cseweb.ucsd.edu/~haozhang/">Prof.Hao Zhang</a>(<a href="https://ucsd.edu/">UCSD</a>).
<br>

His research interests lie in <strong>trustworthy NLP, large language modeling and multi-modal learning</strong>.<br>
</p>


# üî• News
- *2023.05*: üéâ One paper is accepted to ACL 2023!
- *2022.10*: üéâ Two papers are accepted by EMNLP 2022!
- *2022.08*: üéâ One paper is accepted by NAACL 2022!
<!-- - *2022.06*: &nbsp;üéâüéâ Our textual backdoor learning toolkit *OpenBackdoor* has been released. Please check out [here](https://github.com/thunlp/OpenBackdoor)! -->





# üìù Preprints 
\* indicates equal contribution.
- **Generative Pretraining in Multimodality** [\[Paper\]](https://arxiv.org/abs/2307.05222)<br> 
Quan Sun\*, Qiying Yu\*, Yufeng Cui\*, Fan Zhang\*, Xiaosong Zhang\*, Yueze Wang, **Hongcheng Gao**, Jingjing Liu, Tiejun Huang, Xinlong Wang

- **Evaluating the Robustness of Text-to-image Diffusion Models against Real-world Attacks** [\[Paper\]](https://arxiv.org/abs/2306.13103)<br> 
**Hongcheng Gao**, Hao Zhang, Yinpeng Dong, Zhijie Deng. <br>
<!-- *Under Review by **NeurIPS 2023*** -->

- **Revisiting Out-of-distribution Robustness in NLP: Benchmark, Analysis, and LLMs Evaluations** [\[Paper\]](http://arxiv.org/abs/2306.04618)<br>
Lifan Yuan, Yangyi Chen, Ganqu Cui, **Hongcheng Gao**, Fangyuan Zou, Xingyi Cheng, Heng Ji, Zhiyuan Liu, Maosong Sun. <br>
<!-- *Under Review by **NeurIPS 2023*** -->

- **Efficient Detection of LLM-generated Texts with a Bayesian Surrogate Model** [\[Paper\]](https://arxiv.org/abs/2305.16617)<br>
Zhijie Deng\*, **Hongcheng Gao\***, Yibo Miao, Hao Zhang. <br>
<!-- *Under Review by **NeurIPS 2023*** -->

- **DEPP: A Novel Crystal Descriptor and Application in Ionic Batteries Voltage Prediction** <br>
Dongchen Jin\*, **Hongcheng Gao\***, Haoran Luo\*, Linlin He, Chao Yang, Yujie Zheng. <br>
<!-- *Under Review by **npj Computational Materials** (Sister journal of **<font color="dd0000">Nature</font>**)* -->


# üìù Publications 
\* indicates equal contribution.

<!-- <table><tr><td>
    <img src="../images/calibration.png" style="border:1.2px solid #464646;padding:5px;border-radius:10px;box-shadow:1.2px 1.2px #bbbbbb" alt="" width="450px" />&nbsp;</td>
    <td align="left">
    <p>
      <b>A Close Look into the Calibration of Pre-trained Language Models</b>. <a href="https://arxiv.org/abs/2211.00151">[Paper]</a><br>
      Yangyi Chen*, <b>Lifan Yuan*</b>, Ganqu Cui, Zhiyuan Liu, Heng Ji. <br>
      <em><b>What</b></em>: An emperical study on the calibration of PLMs and existing calibration methods. <br>
      <em><b>Results</b></em>: Language models do not learn to be calibrated in training, and existing methods fail to tackle the miscalibration problems.<br>
      <em><b>Insights</b></em>: Learnable calibration methods, which directly collect data to train PLMs on the calibration task, demonstrate a great potential in improving PLMs' calibration.<br>
    </p>
</td></tr></table> -->

**2023**

- **From Adversarial Arms Race to Model-centric Evaluation: Motivating a Unified Automatic Robustness Evaluation Framework** [\[Paper\]](https://arxiv.org/abs/2305.18503)<br>
Yangyi Chen\*, **Hongcheng Gao\***, Ganqu Cui\*, Lifan Yuan, Dehan Kong, Hanlu Wu, Ning Shi, Bo Yuan, Longtao Huang, Hui Xue, Zhiyuan Liu, Maosong Sun, Heng Ji. <br>
*Findings of **ACL 2023***.<br>

**2022**

- **Why Should Adversarial Perturbations be Imperceptible? Rethink the Research Paradigm in Adversarial NLP** [\[Paper\]](https://arxiv.org/abs/2210.10683)<br>
Yangyi Chen\*, **Hongcheng Gao\***, Ganqu Cui, Fanchao Qi, Longtao Huang, Zhiyuan Liu, Maosong Sun. <br>
***EMNLP 2022***.<br>

- **Textual Backdoor Attacks Can Be More Harmful via Two Simple Tricks** [\[Paper\]](https://arxiv.org/abs/2110.08247)<br>
Yangyi Chen\*, Fanchao Qi\*, **Hongcheng Gao**, Zhiyuan Liu, Maosong Sun. <br>
***EMNLP 2022***.<br>


- **Exploring the Universal Vulnerability of Prompt-based Learning Paradigm** [\[Paper\]](https://aclanthology.org/2022.findings-naacl.137)<br>
Lei Xu, Yangyi Chen, Ganqu Cui, **Hongcheng Gao**, Zhiyuan Liu.<br>
*Findings of **NAACL 2022***.<br>


# üíª Projects

- [RobTest](https://github.com/thunlp/RobTest): an open-source toolkit for textual model robustness evaluation .<br>
- [OpenAttack](https://github.com/thunlp/OpenAttack): an open-source Python-based textual adversarial attack toolkit.<br>
- [Emu](https://github.com/baaivision/Emu): an open multimodal generalist for both image-to-text and text-to-image tasks. <br>

<!-- # üìÑ Academic Services
- Journey Reviews:
<a href="https://www.springer.com/journal/10994">Machine Learning</a>,  -->

<!-- **Conference Reviews**

2023: ACL, ARR.

2022: NeurIPS, EMNLP, ARR. --> 


<!-- # üéñ Honors and Awards
- Outstanding Graduate, HUST, 2023
- Optics Valley Morning Star Scholarship, China Optics Valley, 2022
- Scholarship for Scientific and Technological Innovation, HUST, 2022
- National Scholarship, China, 2020
- Outstanding Undergraduate, HUST, 2020
- Merit Student, HUST, 2020
- First Prize in Provinces, Chinese Chemistry Olympiad, 2018 -->

# üìñ Experiences

- *2018.09 - 2023.06*, Undergraduate Student at Chongqing University.
- *2021.06 - 2023.06*, Intern at THUNLP, Tsinghua University. Mentor: <a href="http://nlp.csai.tsinghua.edu.cn/~lzy/">Prof. Zhiyuan Liu</a>

<!-- # üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# üíª Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China. -->